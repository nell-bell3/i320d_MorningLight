{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4e61197",
        "outputId": "bbd39963-bbee-4f56-b454-1c1035d7c562"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "NUMERIC_COLS = ['age', 'listening_time', 'songs_played_per_day', 'skip_rate', 'ads_listened_per_week']\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def load_and_prepare():\n",
        "    df = pd.read_csv(\"spotify_churn_32000.csv\")\n",
        "    df = df.drop_duplicates().dropna()\n",
        "\n",
        "    features = ['gender','age','country','subscription_type',\n",
        "                'listening_time','songs_played_per_day','skip_rate',\n",
        "                'device_type','ads_listened_per_week','offline_listening']\n",
        "\n",
        "    churn_features_df = df[features].copy()\n",
        "\n",
        "    mc_features_columns = ['gender','country','subscription_type','device_type']\n",
        "\n",
        "    encoders = {}\n",
        "    ohe_frames = []\n",
        "    for col in mc_features_columns:\n",
        "        enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "        arr = enc.fit_transform(churn_features_df[[col]])\n",
        "        cols = [f\"{col}_{c}\" for c in enc.categories_[0]]\n",
        "        ohe_frames.append(pd.DataFrame(arr, columns=cols, index=churn_features_df.index))\n",
        "        encoders[col] = {'enc': enc, 'cols': cols}\n",
        "\n",
        "    churn_features_transformed_df = pd.concat([churn_features_df.reset_index(drop=True)] + ohe_frames, axis=1)\n",
        "    churn_features_transformed_df = churn_features_transformed_df.drop(columns=mc_features_columns, axis=1)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    churn_features_transformed_df[NUMERIC_COLS] = scaler.fit_transform(churn_features_transformed_df[NUMERIC_COLS])\n",
        "\n",
        "    return df, churn_features_transformed_df, encoders, scaler\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    with open(\"churn_best_model.saved\",\"rb\") as f:\n",
        "        m = pickle.load(f)\n",
        "    return m\n",
        "\n",
        "def vector_from_inputs(inputs, encoders, scaler, feature_order_df):\n",
        "    base = pd.DataFrame([inputs])\n",
        "\n",
        "    ohe_parts = []\n",
        "    for col, meta in encoders.items():\n",
        "        enc = meta['enc']\n",
        "        cols = meta['cols']\n",
        "        arr = enc.transform(base[[col]])\n",
        "        ohe_parts.append(pd.DataFrame(arr, columns=cols))\n",
        "\n",
        "    vect = pd.concat([base.reset_index(drop=True)] + ohe_parts, axis=1)\n",
        "    vect = vect.drop(columns=list(encoders.keys()), axis=1)\n",
        "\n",
        "    vect[NUMERIC_COLS] = scaler.transform(vect[NUMERIC_COLS])\n",
        "\n",
        "    vect = vect.reindex(columns=feature_order_df.columns, fill_value=0)\n",
        "    return vect.values.flatten()\n",
        "\n",
        "def get_scaler_index(col_name):\n",
        "    \"\"\"Returns the index of a column in the scaler's array\"\"\"\n",
        "    return NUMERIC_COLS.index(col_name)\n",
        "\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Churn Intervention Simulator\")\n",
        "st.title(\"Interactive Churn Intervention Simulator\")\n",
        "\n",
        "raw_df, feature_df, encoders, scaler = load_and_prepare()\n",
        "model = load_model()\n",
        "\n",
        "left, mid, right = st.columns([1,1,1])\n",
        "with left:\n",
        "    st.header(\"1) Choose user profile\")\n",
        "    plan = st.selectbox(\"Subscription Type\", options=['Free','Premium','Family','Student'])\n",
        "    gender = st.selectbox(\"Gender\", options=sorted(raw_df['gender'].unique()))\n",
        "    country = st.selectbox(\"Country\", options=sorted(raw_df['country'].unique()))\n",
        "    device = st.selectbox(\"Device\", options=sorted(raw_df['device_type'].unique()))\n",
        "\n",
        "    age = st.slider(\"Age\", 13, 80, 28)\n",
        "    listening_time = st.slider(\"Listening time (min/day)\", 0, 300, 60)\n",
        "    songs_played = st.slider(\"Songs played per day\", 0, 200, 30)\n",
        "    skip_rate = st.slider(\"Skip rate (0-1)\", 0.0, 1.0, 0.25, step=0.01)\n",
        "    ads = st.slider(\"Ads listened per week\", 0, 60, 6)\n",
        "    offline = st.selectbox(\"Offline listening\", options=[0,1], index=0)\n",
        "\n",
        "    if st.button(\"Calculate base risk\"):\n",
        "        user_inputs = {\n",
        "            'gender': gender, 'age': age, 'country': country, 'subscription_type': plan,\n",
        "            'listening_time': listening_time, 'songs_played_per_day': songs_played,\n",
        "            'skip_rate': skip_rate, 'device_type': device,\n",
        "            'ads_listened_per_week': ads, 'offline_listening': offline\n",
        "        }\n",
        "        user_vec = vector_from_inputs(user_inputs, encoders, scaler, feature_df)\n",
        "        base_prob = model.predict_proba(user_vec.reshape(1,-1))[:,1][0]\n",
        "\n",
        "        st.session_state['user_inputs'] = user_inputs\n",
        "        st.session_state['vec'] = user_vec\n",
        "        st.session_state['base_prob'] = float(base_prob)\n",
        "        st.session_state['cur_prob'] = float(base_prob)\n",
        "        st.session_state['budget'] = 0.0\n",
        "        st.session_state['actions'] = []\n",
        "        st.session_state['use_counts'] = {'ad_detox':0, 'engage_boost':0, 'mobile_msg':0, 'country_msg':0, 'premium_trial':0}\n",
        "        st.success(f\"Base churn prob: {base_prob:.3f}\")\n",
        "\n",
        "with mid:\n",
        "    st.header(\"2) Live Risk & KPI\")\n",
        "    if 'cur_prob' in st.session_state:\n",
        "        st.metric(\"Churn Probability\", f\"{st.session_state['cur_prob']:.3f}\")\n",
        "        st.metric(\"Base Probability\", f\"{st.session_state['base_prob']:.3f}\")\n",
        "        st.metric(\"Budget Spent\", f\"${st.session_state['budget']:.2f}\")\n",
        "        st.write(\"**Actions Log:**\")\n",
        "        for a in st.session_state['actions']:\n",
        "            st.caption(f\"✅ {a['name']} (${a['cost']:.2f}) → Risk: {a['new_prob']:.3f}\")\n",
        "    else:\n",
        "        st.info(\"Set profile and click 'Calculate base risk' to start.\")\n",
        "\n",
        "with right:\n",
        "    st.header(\"3) Apply Interventions\")\n",
        "    if 'vec' in st.session_state:\n",
        "\n",
        "        if st.button(\"Ad Detox (Remove 5 ads, $0.50)\"):\n",
        "            cur = st.session_state['vec'].copy()\n",
        "            col_name = 'ads_listened_per_week'\n",
        "\n",
        "            vec_idx = feature_df.columns.get_loc(col_name)\n",
        "            scaler_idx = get_scaler_index(col_name)\n",
        "\n",
        "            std = np.sqrt(scaler.var_[scaler_idx])\n",
        "            scaled_decrease = 5.0 / std\n",
        "            cur[vec_idx] = cur[vec_idx] - scaled_decrease\n",
        "\n",
        "            newp = model.predict_proba(cur.reshape(1,-1))[:,1][0]\n",
        "            cost = 0.50\n",
        "            st.session_state['budget'] += cost\n",
        "            st.session_state['actions'].append({'name':'Ad Detox', 'cost':cost, 'new_prob':float(newp)})\n",
        "            st.session_state['vec'] = cur\n",
        "            st.session_state['cur_prob'] = float(newp)\n",
        "            st.rerun()\n",
        "\n",
        "        if st.button(\"Engage Boost (Push Discovery, $1)\"):\n",
        "            cur = st.session_state['vec'].copy()\n",
        "\n",
        "            l_col = 'listening_time'\n",
        "            l_idx = feature_df.columns.get_loc(l_col)\n",
        "            l_scale_idx = get_scaler_index(l_col)\n",
        "            l_std = np.sqrt(scaler.var_[l_scale_idx])\n",
        "            cur[l_idx] += (20.0 / l_std)\n",
        "\n",
        "            s_col = 'skip_rate'\n",
        "            s_idx = feature_df.columns.get_loc(s_col)\n",
        "            s_scale_idx = get_scaler_index(s_col)\n",
        "            s_std = np.sqrt(scaler.var_[s_scale_idx])\n",
        "            cur[s_idx] -= (0.05 / s_std)\n",
        "\n",
        "            newp = model.predict_proba(cur.reshape(1,-1))[:,1][0]\n",
        "            cost = 1.00\n",
        "            st.session_state['budget'] += cost\n",
        "            st.session_state['actions'].append({'name':'Engage Boost', 'cost':cost, 'new_prob':float(newp)})\n",
        "            st.session_state['vec'] = cur\n",
        "            st.session_state['cur_prob'] = float(newp)\n",
        "            st.rerun()\n",
        "\n",
        "        if st.button(\"Offer 1-Month Premium ($6)\"):\n",
        "            cur = st.session_state['vec'].copy()\n",
        "            for c in feature_df.columns:\n",
        "                if c.startswith('subscription_'):\n",
        "                    cur[feature_df.columns.get_loc(c)] = 1.0 if c == 'subscription_Premium' else 0.0\n",
        "\n",
        "            a_col = 'ads_listened_per_week'\n",
        "            a_idx = feature_df.columns.get_loc(a_col)\n",
        "            cur[a_idx] = -0.51\n",
        "\n",
        "            newp = model.predict_proba(cur.reshape(1,-1))[:,1][0]\n",
        "            cost = 6.00\n",
        "            st.session_state['budget'] += cost\n",
        "            st.session_state['actions'].append({'name':'Premium Trial', 'cost':cost, 'new_prob':float(newp)})\n",
        "            st.session_state['vec'] = cur\n",
        "            st.session_state['cur_prob'] = float(newp)\n",
        "            st.rerun()\n",
        "\n",
        "    else:\n",
        "        st.write(\"Waiting for profile...\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "if 'actions' in st.session_state and st.session_state['actions']:\n",
        "    st.subheader(\"Impact Trajectory\")\n",
        "    df_plot = pd.DataFrame(\n",
        "        {'Step': ['Start'] + [a['name'] for a in st.session_state['actions']],\n",
        "        'Risk': [st.session_state['base_prob']] + [a['new_prob'] for a in st.session_state['actions']]\n",
        "        }\n",
        "    )\n",
        "    st.line_chart(df_plot.set_index('Step'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download Model\n",
        "##Run these commands to open dashboard\n",
        "cd ~/Downloads streamlit\n",
        "streamlit run app.py"
      ],
      "metadata": {
        "id": "BDPUBLwAoQUT"
      }
    }
  ]
}